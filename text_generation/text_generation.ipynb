{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lecture Notes:\n",
    "\n",
    "* Time series is a sequence of data against time\n",
    "* Models when dealing with sequence data, will use the historical data (past data) to predict the future\n",
    "* Text is also a sequence of data and language models will used it to predict next word and generate sentences\n",
    "* Markov models are used to describe language with the assumptions that the next word relies on the previous one\n",
    "* With this assumption , we don't have a good performance for exemple we can't generate coherent text with Markov models but with neural networks CNNs and RNNs can be used here instead because thet include more context which leads to better results\n",
    "* text generation is one of the most important Task in NLP : the challenge is to generate coherent text : can be used to predict next word when writing emails, poetry, code , etc this can be achived by language models\n",
    "* Transformers with the attention mechanism that helps capture long-range dependanices are very usuful in such NLP task to generate coherent text\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Neural networks with attention mecanisme are very interesting, but I do not think that I'}, {'generated_text': 'Neural networks with attention mecanisme are very, very helpful for the design of neural networks'}]\n"
     ]
    }
   ],
   "source": [
    "# text generation using hugging face \n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# using GPT-2 model by default\n",
    "gen  = pipeline(\"text-generation\")\n",
    "\n",
    "sentence = \"Neural networks with attention mecanisme are very\"\n",
    "\n",
    "print(gen(sentence, num_return_sequences = 2 , max_length = 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data\n",
    "# cd data\n",
    "# wget -nc https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/robert_frost.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "import textwrap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [line.rstrip() for line in open(\"data/robert_frost.txt\")]\n",
    "lines = [line for line in lines if len(line) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "# load pipeline using GPT-2\n",
    "gen = pipeline(\"text-generation\")\n",
    "\n",
    "#set the seed for reproducibility for transformer\n",
    "set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two roads diverged in a yellow wood,\n",
      "[{'generated_text': 'Two roads diverged in a yellow wood, to the West and '\n",
      "                    'south. Two road bridges on two'},\n",
      " {'generated_text': 'Two roads diverged in a yellow wood, which then ran all '\n",
      "                    'the way across, from the intersection'},\n",
      " {'generated_text': 'Two roads diverged in a yellow wood, the trees were a '\n",
      "                    'perfect match. At this moment in'}]\n"
     ]
    }
   ],
   "source": [
    "print(lines[0])\n",
    "pprint(gen(lines[0] , max_length = 20 , num_return_sequences =3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Two roads diverged in a yellow wood, but the road turned into a red\\n'\n",
      " 'one that we have')\n"
     ]
    }
   ],
   "source": [
    "# text cleaning\n",
    "def wrap(x):\n",
    "    return textwrap.fill(x , replace_whitespace=False , fix_sentence_endings=True)\n",
    "\n",
    "out = gen(lines[0], max_length = 20)\n",
    "pprint(wrap(out[0]['generated_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e17245beed66d97676295f18f5af02f52c1ff0b20014505018e20bb50c7c46d6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
